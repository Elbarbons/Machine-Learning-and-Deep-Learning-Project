{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aMi52TN_HfM-"},"outputs":[],"source":["import numpy as np\n","from Resnet import ResNet\n","from PoolingLayer import GeMPool, AdaptiveAVGPool\n","\n","def get_backbone(backbone_arch='resnet50',\n","                 pretrained=True,\n","                 layers_to_freeze=2,\n","                 layers_to_crop=[],):\n","    \"\"\"Helper function that returns the backbone given its name\n","\n","    Args:\n","        backbone_arch (str, optional): . Defaults to 'resnet50'.\n","        pretrained (bool, optional): . Defaults to True.\n","        layers_to_freeze (int, optional): . Defaults to 2.\n","        layers_to_crop (list, optional): This is mostly used with ResNet where we sometimes need to crop the last residual block (ex. [4]). Defaults to [].\n","\n","    Returns:\n","        model: the backbone as a nn.Model object\n","    \"\"\"\n","    if 'resnet' in backbone_arch.lower():\n","        return ResNet(backbone_arch, pretrained, layers_to_freeze, layers_to_crop)\n","\n","\n","def get_aggregator(agg_arch='ConvAP', agg_config={}):\n","    \"\"\"Helper function that returns the aggregation layer given its name.\n","    If you happen to make your own aggregator, you might need to add a call\n","    to this helper function.\n","\n","    Args:\n","        agg_arch (str, optional): the name of the aggregator. Defaults to 'ConvAP'.\n","        agg_config (dict, optional): this must contain all the arguments needed to instantiate the aggregator class. Defaults to {}.\n","\n","    Returns:\n","        nn.Module: the aggregation layer\n","    \"\"\"\n","\n","    if 'gem' in agg_arch.lower():\n","        if agg_config == {}:\n","            agg_config['p'] = 3\n","        else:\n","            assert 'p' in agg_config\n","        return GeMPool(**agg_config)\n","\n","    elif 'avg' in agg_arch.lower():\n","        return AdaptiveAVGPool()\n","\n","\n","\n","\n","\n","# -------------------------------------\n","def print_nb_params(m):\n","    \"\"\"Prints the numbe of trainable parameters in the model\n","\n","    Args:\n","        m (nn.Module): PyTorch model\n","    \"\"\"\n","    model_parameters = filter(lambda p: p.requires_grad, m.parameters())\n","    params = sum([np.prod(p.size()) for p in model_parameters])\n","    print(f'Trainable parameters: {params/1e6:.3}M')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMSIZJd6FiCssXFUbeVUggp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
