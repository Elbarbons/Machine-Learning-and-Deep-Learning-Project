{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdn0vQ/YPo7N4+R2+QnYrU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6T_wQE6kHjVb"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","\n","class ResNet(nn.Module):\n","    def __init__(self,\n","                 model_name='resnet50',\n","                 pretrained=True,\n","                 layers_to_freeze=2,\n","                 layers_to_crop=[],\n","                 ):\n","        \"\"\"Class representing the resnet backbone used in the pipeline\n","        we consider resnet network as a list of 5 blocks (from 0 to 4),\n","        layer 0 is the first conv+bn and the other layers (1 to 4) are the rest of the residual blocks\n","        we don't take into account the global pooling and the last fc\n","\n","        Args:\n","            model_name (str, optional): The architecture of the resnet backbone to instanciate. Defaults to 'resnet50'.\n","            pretrained (bool, optional): Whether pretrained or not. Defaults to True.\n","            layers_to_freeze (int, optional): The number of residual blocks to freeze (starting from 0) . Defaults to 2.\n","            layers_to_crop (list, optional): Which residual layers to crop, for example [3,4] will crop the third and fourth res blocks. Defaults to [].\n","\n","        Raises:\n","            NotImplementedError: if the model_name corresponds to an unknown architecture.\n","        \"\"\"\n","        super().__init__()\n","        self.model_name = model_name.lower()\n","        self.layers_to_freeze = layers_to_freeze\n","\n","        if pretrained:\n","            # the new naming of pretrained weights, you can change to V2 if desired.\n","            weights = 'IMAGENET1K_V1'\n","        else:\n","            weights = None\n","\n","        if 'swsl' in model_name or 'ssl' in model_name:\n","            # These are the semi supervised and weakly semi supervised weights from Facebook\n","            self.model = torch.hub.load(\n","                'facebookresearch/semi-supervised-ImageNet1K-models', model_name)\n","        else:\n","            if 'resnext50' in model_name:\n","                self.model = torchvision.models.resnext50_32x4d(\n","                    weights=weights)\n","            elif 'resnet50' in model_name:\n","                self.model = torchvision.models.resnet50(weights=weights)\n","            elif '101' in model_name:\n","                self.model = torchvision.models.resnet101(weights=weights)\n","            elif '152' in model_name:\n","                self.model = torchvision.models.resnet152(weights=weights)\n","            elif '34' in model_name:\n","                self.model = torchvision.models.resnet34(weights=weights)\n","            elif '18' in model_name:\n","                # self.model = torchvision.models.resnet18(pretrained=False)\n","                self.model = torchvision.models.resnet18(weights=weights)\n","            elif 'wide_resnet50_2' in model_name:\n","                self.model = torchvision.models.wide_resnet50_2(\n","                    weights=weights)\n","            else:\n","                raise NotImplementedError(\n","                    'Backbone architecture not recognized!')\n","\n","        # freeze only if the model is pretrained\n","        if pretrained:\n","            if layers_to_freeze >= 0:\n","                self.model.conv1.requires_grad_(False)\n","                self.model.bn1.requires_grad_(False)\n","            if layers_to_freeze >= 1:\n","                self.model.layer1.requires_grad_(False)\n","            if layers_to_freeze >= 2:\n","                self.model.layer2.requires_grad_(False)\n","            if layers_to_freeze >= 3:\n","                self.model.layer3.requires_grad_(False)\n","\n","        # remove the avgpool and most importantly the fc layer\n","        self.model.avgpool = None\n","        self.model.fc = None\n","\n","        if 4 in layers_to_crop:\n","            self.model.layer4 = None\n","        if 3 in layers_to_crop:\n","            self.model.layer3 = None\n","\n","        out_channels = 2048\n","        if '34' in model_name or '18' in model_name:\n","            out_channels = 512\n","\n","        self.out_channels = out_channels // 2 if self.model.layer4 is None else out_channels\n","        self.out_channels = self.out_channels // 2 if self.model.layer3 is None else self.out_channels\n","\n","    def forward(self, x):\n","        x = self.model.conv1(x)\n","        x = self.model.bn1(x)\n","        x = self.model.relu(x)\n","        x = self.model.maxpool(x)\n","        x = self.model.layer1(x)\n","        x = self.model.layer2(x)\n","        if self.model.layer3 is not None:\n","            x = self.model.layer3(x)\n","        if self.model.layer4 is not None:\n","            x = self.model.layer4(x)\n","        return x"]}]}